{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "\n",
    "file=urlopen('https://raw.githubusercontent.com/ellikamishra/Datasets/master/MitreData.json')\n",
    "# file = open('MitreData.json')\n",
    "\n",
    "obj_list = []\n",
    "dict = {}\n",
    "\n",
    "for line in file:\n",
    "    # line=line + '\\n'\n",
    "    obj_list.append(eval(line))\n",
    "\n",
    "new_list = []\n",
    "for item in obj_list:\n",
    "    # if(len(item['tactics'])>1):\n",
    "    #     for tactic in item['tactics']:\n",
    "    #         dict = item\n",
    "    #         dict['tactics'] = tactic\n",
    "    #         new_list.append(dict)\n",
    "    # else:\n",
    "    dict = item\n",
    "    #dict['tactics'] = item['tactics'][0]\n",
    "    new_list.append(dict)\n",
    "\n",
    "df = pd.DataFrame(new_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileD = urlopen('https://raw.githubusercontent.com/ellikamishra/Datasets/master/DataSources.json')\n",
    "\n",
    "objD_list = []\n",
    "for line in fileD:\n",
    "    objD_list.append(eval(line))\n",
    "    \n",
    "df_DS = pd.DataFrame(objD_list)\n",
    "df_DS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tramp_small=pd.read_json('https://raw.githubusercontent.com/center-for-threat-informed-defense/tram/master/tests/data/test-training-data.json')\n",
    "\n",
    "tramp=pd.read_json('https://raw.githubusercontent.com/center-for-threat-informed-defense/tram/master/data/training/bootstrap-training-data.json')\n",
    "\n",
    "df_tramp=tramp['sentences']\n",
    "df_tramp_small=tramp_small['sentences']\n",
    "\n",
    "df_tramp.append(df_tramp_small,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# print(df_tramp[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dict_tr={'id':[],'text':[]}\n",
    "index=0\n",
    "for i in df_tramp:\n",
    "    # print(i['mappings'][0]['attack_id'])\n",
    "    # print(i)\n",
    "    if not i['mappings']:\n",
    "        continue\n",
    "    idv=i['mappings'][0]['attack_id']\n",
    "    \n",
    "    dict_tr['id'].append(idv)\n",
    "    dict_tr['text'].append(i['text'])\n",
    "    \n",
    "df_tr=pd.DataFrame(dict_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb=df.join(df_tr.set_index('id'),on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comb.drop(df.iloc[:, 8:22], inplace = True, axis = 1)\n",
    "df_comb.drop(['subtechniqueof'],axis=1)\n",
    "df_comb.drop(['subtechniques'],axis=1)\n",
    "# df_comb=df_comb.fillna(df_comb.mode().iloc[0])\n",
    "# df_comb.head()\n",
    "for x in df_comb:\n",
    "    # print(df_comb[x])\n",
    "    df_comb[x]=df_comb[x].fillna(method='bfill',axis=0)\n",
    "    df_comb[x]=df_comb[x].fillna(method='ffill',axis=0)\n",
    "    df_comb[x]=df_comb[x].interpolate(method='linear',limit_direction='forward',axis=0)\n",
    "\n",
    "df_comb.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb.drop(['subtechniqueof'],axis=1)\n",
    "df_comb.drop(['subtechniques'],axis=1)\n",
    "# df_comb=df_comb.fillna(df_comb.mode().iloc[0])\n",
    "# df_comb.head()\n",
    "for x in df_comb:\n",
    "    # print(df_comb[x])\n",
    "    df_comb[x]=df_comb[x].fillna(method='bfill',axis=0)\n",
    "    df_comb[x]=df_comb[x].fillna(method='ffill',axis=0)\n",
    "    df_comb[x]=df_comb[x].interpolate(method='linear',limit_direction='forward',axis=0)\n",
    "\n",
    "df_comb.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb['id'].value_counts()\n",
    "tids = df_comb['id'].unique()\n",
    "dict_target = {}\n",
    "dict_tactic= {}\n",
    "i = 0\n",
    "for x in tids:\n",
    "     dict_target[x] = i\n",
    "     dict_tactic[x]=df_comb.loc[df_comb['id']==x,'tactics'].append(df_comb.loc[df_comb['id']==x,'techniquename'])\n",
    "     i = i + 1\n",
    "#print(dict_target)\n",
    "\n",
    "df_comb['num_target']=df_comb['id'].map(dict_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedKFold,StratifiedKFold,StratifiedShuffleSplit,StratifiedGroupKFold,RepeatedStratifiedKFold, GroupShuffleSplit,ShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "\n",
    "X = df_comb.loc[:, df_comb.columns != 'techniquename'].apply(lambda x: \",\".join(x.astype(str)), axis=1)\n",
    "y=df_comb['num_target']\n",
    "\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(2,2),stop_words='english')\n",
    "\n",
    "vect.fit_transform(X)\n",
    "# vect.transform(y)\n",
    "model = MultinomialNB(alpha =0.2)\n",
    "\n",
    "clf=make_pipeline(vect,model)\n",
    "\n",
    "cv = RepeatedKFold(n_splits=4, n_repeats=10, random_state=1)\n",
    "# 0.75257732 0.73966942 0.76033058 0.76239669\n",
    "cvr=RepeatedStratifiedKFold(n_splits=4,n_repeats=10,random_state=1)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# [0.75       0.75773196 0.7622739  0.75452196 0.76744186]\n",
    "\n",
    "sfold=ShuffleSplit(n_splits=6, test_size=0.4, random_state=1)\n",
    "# [0.74580645 0.74967742 0.73935484 0.72645161 0.73419355 0.7483871 ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_id,test_id in kfold.split(X,y):\n",
    "  # X_train,X_test=X[train_id],X[test_id]\n",
    "  clf.fit(X.iloc[train_id],y.iloc[train_id])\n",
    "  clf.predict(X.iloc[test_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_id(num):\n",
    "    #print(dict_target)\n",
    "    for key, value in dict_target.items():\n",
    "        if num == value:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T1558.004 AS-REP Roasting\n",
    "desc = [\"Monitor network traffic for unusual ARP traffic, gratuitous ARP replies may be suspicious. Consider collecting changes to ARP caches across endpoints for signs of ARP poisoning. For example, if multiple IP addresses map to a single MAC address, this could be an indicator that the ARP cache has been poisoned\"] \n",
    "# T1134 Access Token Manipulation\n",
    "desc3=[\"Monitor the file system for files that have the setuid or setgid bits set. Also look for any process API calls for behavior that may be indicative of [Process Injection]\"]\n",
    "desc2 = [\"Suspicious Process Activity- Targeted - Malicious Start Menu Startup Modification Analytic -A2B - EDR \"]\n",
    "# test = vect.transform(desc3)\n",
    "# pred=cross_val_predict(clf, X, y, cv=cvr)\n",
    "\n",
    "t1=[\"Service providers have significant access to customer networks, enabling an attacker who had compromised a service provider to move laterally into the network of the service provider customer \"]\n",
    "pred= clf.predict(t1)\n",
    "print(pred)\n",
    "\n",
    "\n",
    "r1=predict_id(pred)\n",
    "r = dict_tactic[r1]\n",
    "print (r)\n",
    "print(r1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
